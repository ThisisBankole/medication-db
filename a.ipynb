{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.rxlist.com'\n",
    "\n",
    "def scrape_alphabet_links():\n",
    "    response = requests.get(f'{base_url}/drugs/alpha_a.htm')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for li in soup.select('div#A_Z ul li'):\n",
    "        a = li.find('a')\n",
    "        link = a['href']\n",
    "        links.append(base_url + link)\n",
    "\n",
    "    return links\n",
    "\n",
    "def scrape_drug_links(alphabet_link):\n",
    "    response = requests.get(alphabet_link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for li in soup.select('div.AZ_results ul li'):\n",
    "        a = li.find('a')\n",
    "        link = a['href']\n",
    "        links.append(link)\n",
    "\n",
    "    return links\n",
    "\n",
    "def scrape_drug_details(drug_link):\n",
    "    response = requests.get(drug_link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    details = {}\n",
    "\n",
    "    for li in soup.select('div.toc.link ul.fda_toc li'):\n",
    "        a = li.find('a')\n",
    "        detail_name = a.text\n",
    "\n",
    "        detail_link = drug_link + a['href'].split('#')[1]\n",
    "\n",
    "        detail_response = requests.get(detail_link)\n",
    "        detail_soup = BeautifulSoup(detail_response.text, 'html.parser')\n",
    "\n",
    "        detail_text = detail_soup.text.strip()\n",
    "\n",
    "        details[detail_name] = detail_text\n",
    "\n",
    "    return details\n",
    "\n",
    "def main():\n",
    "    alphabet_links = scrape_alphabet_links()\n",
    "    \n",
    "    # Only use the first link, which should be the link to the 'A' page\n",
    "    alphabet_link = alphabet_links[0]\n",
    "\n",
    "    all_drugs = []\n",
    "\n",
    "    for alphabet_link in alphabet_links:\n",
    "        drug_links = scrape_drug_links(alphabet_link)\n",
    "\n",
    "        for drug_link in drug_links:\n",
    "            drug_details = scrape_drug_details(drug_link)\n",
    "            all_drugs.append(drug_details)\n",
    "\n",
    "    keys = all_drugs[0].keys()\n",
    "\n",
    "    with open('drugs.csv', 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(all_drugs)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
